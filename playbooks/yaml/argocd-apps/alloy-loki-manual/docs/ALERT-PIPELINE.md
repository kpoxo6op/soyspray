# Loki Alert Pipeline: From Logs to Telegram

## Complete Flow Diagram

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: LOG COLLECTION                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Alloy DaemonSet      â”‚          â”‚ Alloy Events         â”‚
â”‚ (on every node)      â”‚          â”‚ (single deployment)  â”‚
â”‚                      â”‚          â”‚                      â”‚
â”‚ Collects:            â”‚          â”‚ Collects:            â”‚
â”‚ /var/log/pods/*/*.logâ”‚          â”‚ K8s Events API       â”‚
â”‚                      â”‚          â”‚                      â”‚
â”‚ Labels added:        â”‚          â”‚ Labels added:        â”‚
â”‚ - job=kubernetes-podsâ”‚          â”‚ - job=kubernetes-events
â”‚ - namespace          â”‚          â”‚ - namespace          â”‚
â”‚ - pod                â”‚          â”‚ - reason             â”‚
â”‚ - container          â”‚          â”‚ - type (Warning/Normal)
â”‚ - cluster=soyspray   â”‚          â”‚ - involved_object_*  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                  â”‚
          â”‚ HTTP Push                        â”‚ HTTP Push
          â”‚ :3100/loki/api/v1/push          â”‚ :3100/loki/api/v1/push
          â”‚                                  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: LOG STORAGE & INDEXING                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Loki StatefulSet         â”‚
          â”‚ (monitoring namespace)   â”‚
          â”‚                          â”‚
          â”‚ Components:              â”‚
          â”‚ 1. Ingester             â”‚â—„â”€â”€ Receives logs from Alloy
          â”‚ 2. Querier              â”‚â—„â”€â”€ Queried by Ruler
          â”‚ 3. Ruler âš¡             â”‚â—„â”€â”€ Evaluates alert rules
          â”‚ 4. Compactor            â”‚
          â”‚                          â”‚
          â”‚ Storage:                 â”‚
          â”‚ /var/loki/chunks/       â”‚
          â”‚ /var/loki/index/        â”‚
          â”‚ (50Gi Longhorn PVC)     â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â”‚ Mounts ConfigMaps:
                    â”‚ - /etc/loki/config.yaml (loki-config)
                    â”‚ - /etc/loki/rules/*.yaml (projected volume) â—„â”€â”€ YOUR RULES HERE!
                    â”‚   â”œâ”€â”€ loki-rules-kubernetes
                    â”‚   â””â”€â”€ loki-rules-backup
                    â”‚
                    â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: RULE EVALUATION (Loki Ruler Component)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Projected Volume: Rules ConfigMaps   â”‚
          â”‚ (/etc/loki/rules/)                  â”‚
          â”‚                                     â”‚
          â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
          â”‚ â”‚ loki-rules-kubernetes ConfigMapâ”‚ â”‚
          â”‚ â”‚                                 â”‚ â”‚
          â”‚ â”‚ â€¢ kubernetes-critical.yaml     â”‚ â”‚
          â”‚ â”‚   - KubernetesPodCrashLoopingLogsâ”‚ â”‚
          â”‚ â”‚                                 â”‚ â”‚
          â”‚ â”‚ â€¢ application-errors.yaml      â”‚ â”‚
          â”‚ â”‚   - ApplicationErrorBurst       â”‚ â”‚
          â”‚ â”‚     count_over_time(...|~ "error")â”‚ â”‚
          â”‚ â”‚                                 â”‚ â”‚
          â”‚ â”‚ â€¢ storage-mount-failures.yaml  â”‚ â”‚
          â”‚ â”‚   - VolumeMountAttachFailures   â”‚ â”‚
          â”‚ â”‚     |~ "FailedMount|Failed..." â”‚ â”‚
          â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
          â”‚                                     â”‚
          â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
          â”‚ â”‚ loki-rules-backup ConfigMap    â”‚ â”‚
          â”‚ â”‚                                 â”‚ â”‚
          â”‚ â”‚ â€¢ immich-backup.yaml           â”‚ â”‚
          â”‚ â”‚ â€¢ immich-backup-events.yaml    â”‚ â”‚
          â”‚ â”‚ â€¢ cnpg-backup.yaml             â”‚ â”‚
          â”‚ â”‚ â€¢ backup-error-burst.yaml       â”‚ â”‚
          â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â”‚ Ruler runs LogQL queries every 1m
                           â”‚ Example: count_over_time({job="kubernetes-pods"}
                           â”‚          |~ "error"[5m]) > 50
                           â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Loki Ruler evaluates:                â”‚
          â”‚                                      â”‚
          â”‚ FOR ApplicationErrorBurst:           â”‚
          â”‚ 1. Query logs: job=kubernetes-pods   â”‚
          â”‚ 2. Filter: |~ "(?i)\b(error|fatal)\b"â”‚
          â”‚ 3. Count over 5m window              â”‚
          â”‚ 4. Group by (namespace, pod)         â”‚
          â”‚ 5. Threshold: > 50 lines             â”‚
          â”‚ 6. Wait: 5m (for: 5m)                â”‚
          â”‚ 7. IF TRUE â†’ Fire Alert              â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ Alert Payload:
                         â”‚ {
                         â”‚   "alertname": "ApplicationErrorBurst",
                         â”‚   "namespace": "media",
                         â”‚   "pod": "radarr-7d8f9c-xyz",
                         â”‚   "severity": "warning",
                         â”‚   "summary": "Error burst in media/radarr-7d8f9c-xyz"
                         â”‚ }
                         â”‚
                         â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: ALERT ROUTING (Alertmanager)                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Alertmanager                          â”‚
          â”‚ (deployed by kube-prometheus-stack)   â”‚
          â”‚                                       â”‚
          â”‚ Configuration:                        â”‚
          â”‚ - LoadBalancer: 192.168.50.206        â”‚
          â”‚ - Config: prometheus/values.yaml      â”‚
          â”‚                                       â”‚
          â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
          â”‚ â”‚ Route Configuration:              â”‚ â”‚
          â”‚ â”‚                                   â”‚ â”‚
          â”‚ â”‚ route:                            â”‚ â”‚
          â”‚ â”‚   group_by: ["alertname"]         â”‚ â”‚
          â”‚ â”‚   group_wait: 30s                 â”‚ â”‚
          â”‚ â”‚   group_interval: 5m              â”‚ â”‚
          â”‚ â”‚   repeat_interval: 4h             â”‚ â”‚
          â”‚ â”‚   receiver: "telegram"            â”‚ â”‚
          â”‚ â”‚   routes:                         â”‚ â”‚
          â”‚ â”‚     - matchers:                   â”‚ â”‚
          â”‚ â”‚       - severity=~"warning|critical"â”‚ â”‚
          â”‚ â”‚       receiver: "telegram"        â”‚ â”‚
          â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
          â”‚                                       â”‚
          â”‚ Processing:                           â”‚
          â”‚ 1. Receive alert from Loki Ruler      â”‚
          â”‚ 2. Check severity (warning/critical)  â”‚
          â”‚ 3. Group by alertname                 â”‚
          â”‚ 4. Wait 30s for more alerts           â”‚
          â”‚ 5. Send to telegram receiver          â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: TELEGRAM NOTIFICATION                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Telegram Receiver Configuration:     â”‚
          â”‚                                      â”‚
          â”‚ receivers:                           â”‚
          â”‚   - name: "telegram"                 â”‚
          â”‚     telegram_configs:                â”‚
          â”‚       - api_url: "https://api.telegram.org"
          â”‚         bot_token_file: /etc/alertmanager/telegram/
          â”‚                         PROMETHEUS_TELEGRAM_BOT_TOKEN
          â”‚         chat_id: 336642153           â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ Secret mounted from:
                         â”‚ alertmanager-telegram-secret
                         â”‚ (contains bot token)
                         â”‚
                         â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Telegram API                         â”‚
          â”‚ https://api.telegram.org             â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  ğŸ“± Your Telegram                    â”‚
          â”‚                                      â”‚
          â”‚  ğŸ”´ [FIRING:1] ApplicationErrorBurst â”‚
          â”‚                                      â”‚
          â”‚  Error burst in media/radarr-xyz     â”‚
          â”‚                                      â”‚
          â”‚  More than 50 log lines containing   â”‚
          â”‚  'error' or 'fatal' were observed    â”‚
          â”‚  in 5m for pod media/radarr-xyz.     â”‚
          â”‚  Investigate recent deployments...   â”‚
          â”‚                                      â”‚
          â”‚  Labels:                             â”‚
          â”‚    alertname: ApplicationErrorBurst  â”‚
          â”‚    namespace: media                  â”‚
          â”‚    pod: radarr-7d8f9c-xyz           â”‚
          â”‚    severity: warning                 â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Configuration File Locations

### 1. Log Collection Configuration
**Location**: `playbooks/yaml/argocd-apps/alloy-loki-manual/`
- `alloy-configmap.yaml` - Pod logs collection
- `alloy-events-configmap.yaml` - Kubernetes events collection
- `alloy-daemonset.yaml` - DaemonSet running on every node
- `alloy-events-deployment.yaml` - Events collector deployment

### 2. Loki Storage & Rules
**Location**: `playbooks/yaml/argocd-apps/alloy-loki-manual/`
- `loki-configmap.yaml` - Loki server configuration
  - Line 64-73: Ruler configuration pointing to Alertmanager
- `loki-rules-kubernetes.yaml` - **Platform & Kubernetes Rules** âš¡
  - `kubernetes-critical.yaml` - KubernetesPodCrashLoopingLogs
  - `application-errors.yaml` - ApplicationErrorBurst
  - `storage-mount-failures.yaml` - VolumeMountAttachFailures
- `loki-rules-backup.yaml` - **Backup & Database Rules** âš¡
  - `immich-backup.yaml` - ImmichMediaBackupFailureImmediate
  - `immich-backup-events.yaml` - ImmichMediaBackupBackoffLimitExceeded
  - `cnpg-backup.yaml` - CNPGBackupBarmanError, CNPGWalArchiveFailure
  - `backup-error-burst.yaml` - BackupErrorBurst
- `loki-statefulset.yaml` - Uses projected volume to mount both rule ConfigMaps

### 3. Alertmanager Configuration
**Location**: `playbooks/yaml/argocd-apps/prometheus/`
- `values.yaml` - Lines 145-184
  - Telegram bot token mount
  - Route configuration
  - Receiver configuration

## How Rules Work

### Example: ApplicationErrorBurst

```yaml
- alert: ApplicationErrorBurst
  expr: |
    sum by (namespace, pod) (
      count_over_time({cluster="soyspray", job="kubernetes-pods"} |~ "(?i)\b(error|fatal)\b" [5m])
    ) > 50
  for: 5m
```

**Step-by-step execution:**

1. **LogQL Query**: `{cluster="soyspray", job="kubernetes-pods"}`
   - Selects all pod logs from your cluster

2. **Log Filter**: `|~ "(?i)\b(error|fatal)\b"`
   - Case-insensitive regex match for "error" or "fatal" words

3. **Count**: `count_over_time(...[5m])`
   - Counts matching log lines in 5-minute window

4. **Group**: `sum by (namespace, pod)`
   - Groups results per namespace+pod combination

5. **Threshold**: `> 50`
   - Fires if more than 50 error lines found

6. **Pending**: `for: 5m`
   - Alert must be true for 5 minutes before firing

7. **Labels**: `severity: warning`
   - Sets alert severity for routing

## Label Flow

Labels are consistently applied through the pipeline:

```
Alloy Collection â†’ Loki Storage â†’ Rule Evaluation â†’ Alert
  cluster=soyspray   cluster=soyspray   namespace=media    namespace=media
  job=kubernetes-pods job=kubernetes-pods pod=radarr-xyz   pod=radarr-xyz
  namespace=media     namespace=media                      severity=warning
  pod=radarr-xyz      pod=radarr-xyz                       alertname=...
```

## Why This Works

### Log-Based vs Metric-Based Alerts

**Metrics** (Prometheus):
- âœ… CPU, memory, disk usage
- âœ… Request rates, latencies
- âœ… Counters, gauges, histograms
- âŒ Cannot detect "error" in logs
- âŒ Cannot parse event messages

**Logs** (Loki):
- âœ… Error message patterns
- âœ… Kubernetes event messages
- âœ… Application-specific failures
- âœ… Text pattern matching
- âŒ Not suitable for numeric metrics

**Your setup has BOTH!**
- Prometheus monitors metrics
- Loki monitors logs
- Both send alerts to same Alertmanager
- Both route to same Telegram bot

## Integration Points

### 1. Loki â†’ Alertmanager
```yaml
# loki-configmap.yaml
ruler:
  alertmanager_url: http://alertmanager-operated.monitoring.svc:9093
```

### 2. Prometheus â†’ Loki (Metrics)
```yaml
# loki-servicemonitor.yaml
# Prometheus scrapes Loki's /metrics endpoint
# (monitors Loki's own health, not for alerts)
```

### 3. Alloy â†’ Loki (Logs)
```yaml
# alloy-configmap.yaml
loki.write "default" {
  endpoint {
    url = "http://loki.monitoring.svc.cluster.local:3100/loki/api/v1/push"
  }
}
```

### 4. Alertmanager â†’ Telegram
```yaml
# prometheus/values.yaml
telegram_configs:
  - api_url: "https://api.telegram.org"
    bot_token_file: /etc/alertmanager/telegram/PROMETHEUS_TELEGRAM_BOT_TOKEN
    chat_id: 336642153
```

## Testing the Pipeline

### 1. Generate Test Logs
```bash
# Create a pod that logs errors
kubectl run error-test --image=busybox --restart=Never -- sh -c '
  for i in $(seq 1 100); do
    echo "ERROR: Test error message $i"
    sleep 1
  done
'
```

### 2. Check Loki Ingestion
```bash
# Port-forward to Loki
kubectl port-forward -n monitoring svc/loki 3100:3100

# Query logs via LogQL
curl 'http://localhost:3100/loki/api/v1/query' \
  --data-urlencode 'query={pod="error-test"} |= "ERROR"'
```

### 3. Check Ruler Evaluation
```bash
# Check Loki ruler API
curl http://localhost:3100/loki/api/v1/rules

# Should show your rules and their state
```

### 4. Check Alertmanager
```bash
# Port-forward to Alertmanager
kubectl port-forward -n monitoring svc/alertmanager-operated 9093:9093

# View active alerts
curl http://localhost:9093/api/v2/alerts
```

### 5. Check Telegram
- Wait 5 minutes (for: 5m)
- Alert should fire to Telegram chat 336642153

## Troubleshooting

### Alert Not Firing?

1. **Check Loki has logs**:
   ```bash
   kubectl logs -n monitoring loki-0 | grep "ingester"
   ```

2. **Check Ruler is running**:
   ```bash
   kubectl logs -n monitoring loki-0 | grep "ruler"
   ```

3. **Check rules are loaded**:
   ```bash
   kubectl exec -n monitoring loki-0 -- ls -la /etc/loki/rules/
   ```

4. **Check Alertmanager connectivity**:
   ```bash
   kubectl exec -n monitoring loki-0 -- wget -O- \
     http://alertmanager-operated.monitoring.svc:9093/-/healthy
   ```

### Alert Fires But No Telegram?

1. **Check Alertmanager config**:
   ```bash
   kubectl get secret -n monitoring alertmanager-kube-prometheus-stack-alertmanager \
     -o jsonpath='{.data.alertmanager\.yaml}' | base64 -d
   ```

2. **Check Telegram secret**:
   ```bash
   kubectl get secret -n monitoring alertmanager-telegram-secret
   ```

3. **Check Alertmanager logs**:
   ```bash
   kubectl logs -n monitoring alertmanager-kube-prometheus-stack-alertmanager-0
   ```

## Summary

**Your complete observability stack:**

```
Logs (Alloy) â”€â”€â”
               â”œâ”€â”€â–º Loki â”€â”€â–º Ruler â”€â”€â”
Events (Alloy)â”€â”˜                     â”‚
                                     â”œâ”€â”€â–º Alertmanager â”€â”€â–º Telegram ğŸ“±
Metrics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Prometheus â”€â”€â”€â”€â”€â”˜
```

- **2 log pipelines**: Pod logs + K8s events
- **1 metrics pipeline**: Prometheus scraping
- **3 alert rules**: Errors, crashes, storage failures
- **1 notification channel**: Telegram
- **100% GitOps**: All config in this repo

